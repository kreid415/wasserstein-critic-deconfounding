{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "# Find all checkpoints in the checkpoints directory\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44edf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from wcd_vae.data import get_dataloader_from_adata\n",
    "from wcd_vae.model import VAE, VAEConfig, Discriminator, VAEDiscriminator, VAEWasserstein, VAE_OT\n",
    "from wcd_vae.metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d85292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aee14a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.11/site-packages/anndata/_core/anndata.py:602: FutureWarning: You are attempting to set `X` to a matrix on a view which has non-unique indices. The resulting `adata.X` will likely not equal the value to which you set it. To avoid this potential issue, please make a copy of the data first. In the future, this operation will throw an error.\n",
      "  warnings.warn(msg, FutureWarning, stacklevel=1)\n",
      "/tmp/ipykernel_219471/2002759975.py:10: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n",
      "  anndata.X = anndata.layers[\"counts\"]\n"
     ]
    }
   ],
   "source": [
    "# Load the anndata object (adjust path if needed)\n",
    "anndata_path = \"../data/vu_2022_ay_wh.h5ad\"\n",
    "anndata = ad.read_h5ad(anndata_path)\n",
    "anndata.layers[\"normalized\"] = anndata.X\n",
    "\n",
    "# Find/subset HVGs & swap to raw counts\n",
    "import scanpy as sc\n",
    "sc.pp.highly_variable_genes(anndata, n_top_genes=3000, batch_key=\"sample\")\n",
    "anndata = anndata[:, anndata.var[\"highly_variable\"]]\n",
    "anndata.X = anndata.layers[\"counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bbab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE config (should match training)\n",
    "config = VAEConfig(\n",
    "    input_dim=anndata.shape[1],\n",
    "    latent_dim=128,\n",
    "    encoder_hidden_dims=[512, 256],\n",
    "    decoder_hidden_dims=[256, 512],\n",
    "    dropout=0.2,\n",
    "    batchsize=128,\n",
    "    num_epochs=100_000,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-5,\n",
    "    kl_anneal_start=0,\n",
    "    kl_anneal_end=100,\n",
    "    kl_anneal_max=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "940e1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test loader\n",
    "_, test_loader, domain_encoder, cell_encoder = get_dataloader_from_adata(\n",
    "    anndata, by=\"age\", batch_size=config.batchsize, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6eca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoints: ['/workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints/train_vae-epoch=20043-val_loss=42.99.ckpt', '/workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints/train_vae_c-epoch=50248-val_loss=46.09.ckpt', '/workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints/train_vae_d-epoch=99500-val_loss=40.09.ckpt', '/workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints/train_vae_uot-epoch=21285-val_loss=48.59.ckpt']\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = \"/workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints\"\n",
    "ckpt_files = sorted(glob.glob(os.path.join(ckpt_dir, \"*.ckpt\")))\n",
    "print(\"Found checkpoints:\", ckpt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a06e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_eval(model_class, ckpt_path, config, test_loader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    # Instantiate and load model\n",
    "    if model_class == VAE:\n",
    "        model = VAE.load_from_checkpoint(ckpt_path, config=config, linear_decoder=True)\n",
    "        eval_model = model\n",
    "    elif model_class == VAEDiscriminator:\n",
    "        vae = VAE(config, linear_decoder=True)\n",
    "        critic = Discriminator(config.latent_dim, critic=False)\n",
    "        model = VAEDiscriminator.load_from_checkpoint(ckpt_path, vae=vae, critic=critic)\n",
    "        eval_model = model.vae\n",
    "    elif model_class == VAEWasserstein:\n",
    "        vae = VAE(config, linear_decoder=True)\n",
    "        critic = Discriminator(config.latent_dim, critic=True)\n",
    "        model = VAEWasserstein.load_from_checkpoint(ckpt_path, vae=vae, critic=critic)\n",
    "        eval_model = model.vae\n",
    "    elif model_class == VAE_OT:\n",
    "        model = VAE_OT.load_from_checkpoint(ckpt_path, config=config, linear_decoder=True)\n",
    "        eval_model = model\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model class\")\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    eval_model = eval_model.to(device)\n",
    "    eval_model.eval()\n",
    "\n",
    "    # Compute embeddings\n",
    "    embeddings = []\n",
    "    batches = []\n",
    "    cell_type = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Evaluating {os.path.basename(ckpt_path)}\"):\n",
    "            x, batch_label, cell_label = batch\n",
    "            x, batch_label, cell_label = x.to(device), batch_label.to(device), cell_label.to(device)\n",
    "            mu, logvar = eval_model.encode(x)\n",
    "            z = eval_model.reparameterize(mu, logvar)\n",
    "            embeddings.append(z.cpu())\n",
    "            batches.append(batch_label.cpu())\n",
    "            cell_type.append(cell_label.cpu())\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    batches = torch.cat(batches, dim=0)\n",
    "    cell_type = torch.cat(cell_type, dim=0)\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics_dict = compute_metrics(\n",
    "        embeddings=embeddings,\n",
    "        batch_labels=batches,\n",
    "        cell_type_labels=cell_type,\n",
    "    )\n",
    "    return embeddings, batches, cell_type, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a37289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_eval(model_class, ckpt_path, config, test_loader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    # Instantiate and load model\n",
    "    if model_class == VAE:\n",
    "        model = VAE.load_from_checkpoint(ckpt_path, config=config, linear_decoder=True)\n",
    "        eval_model = model\n",
    "    elif model_class == VAEDiscriminator:\n",
    "        vae = VAE(config, linear_decoder=True)\n",
    "        critic = Discriminator(config.latent_dim, critic=False)\n",
    "        model = VAEDiscriminator.load_from_checkpoint(ckpt_path, vae=vae, critic=critic)\n",
    "        eval_model = model.vae\n",
    "    elif model_class == VAEWasserstein:\n",
    "        vae = VAE(config, linear_decoder=True)\n",
    "        critic = Discriminator(config.latent_dim, critic=True)\n",
    "        model = VAEWasserstein.load_from_checkpoint(ckpt_path, vae=vae, critic=critic)\n",
    "        eval_model = model.vae\n",
    "    elif model_class == VAE_OT:\n",
    "        model = VAE_OT.load_from_checkpoint(ckpt_path, config=config, linear_decoder=True)\n",
    "        eval_model = model\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model class\")\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    eval_model = eval_model.to(device)\n",
    "    eval_model.eval()\n",
    "\n",
    "    # Compute embeddings\n",
    "    embeddings = []\n",
    "    batches = []\n",
    "    cell_type = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Evaluating {os.path.basename(ckpt_path)}\"):\n",
    "            x, batch_label, cell_label = batch\n",
    "            x, batch_label, cell_label = x.to(device), batch_label.to(device), cell_label.to(device)\n",
    "            mu, logvar = eval_model.encode(x)\n",
    "            z = eval_model.reparameterize(mu, logvar)\n",
    "            embeddings.append(z.cpu())\n",
    "            batches.append(batch_label.cpu())\n",
    "            cell_type.append(cell_label.cpu())\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    batches = torch.cat(batches, dim=0)\n",
    "    cell_type = torch.cat(cell_type, dim=0)\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics_dict = compute_metrics(\n",
    "        embeddings=embeddings,\n",
    "        batch_labels=batches,\n",
    "        cell_type_labels=cell_type,\n",
    "    )\n",
    "    return embeddings, batches, cell_type, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a5a3dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint /workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints/train_vae-epoch=20043-val_loss=42.99.ckpt as vae-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train_vae-epoch=20043-val_loss=42.99.ckpt: 100%|██████████| 43/43 [00:00<00:00, 580.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for vae-:\n",
      "  batch_entropy: 0.6931471824645996\n",
      "  ilisi_batch: 2.0\n",
      "  clisi_celltype: 1.2195122241973877\n",
      "  silhouette_score: -0.0214417465031147\n",
      "  normalized_mutual_info: 0.00041299566030934126\n",
      "Evaluating checkpoint /workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints/train_vae_c-epoch=50248-val_loss=46.09.ckpt as vae_c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train_vae_c-epoch=50248-val_loss=46.09.ckpt: 100%|██████████| 43/43 [00:00<00:00, 634.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for vae_c:\n",
      "  batch_entropy: 0.6931471824645996\n",
      "  ilisi_batch: 2.0\n",
      "  clisi_celltype: 1.2195122241973877\n",
      "  silhouette_score: -0.023939337581396103\n",
      "  normalized_mutual_info: 0.00041299566030934126\n",
      "Evaluating checkpoint /workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints/train_vae_d-epoch=99500-val_loss=40.09.ckpt as vae_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train_vae_d-epoch=99500-val_loss=40.09.ckpt: 100%|██████████| 43/43 [00:00<00:00, 638.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for vae_d:\n",
      "  batch_entropy: 0.6931471824645996\n",
      "  ilisi_batch: 2.0\n",
      "  clisi_celltype: 1.2195122241973877\n",
      "  silhouette_score: -0.0258098766207695\n",
      "  normalized_mutual_info: 0.00041299566030934126\n",
      "Evaluating checkpoint /workspaces/wasserstein-critic-deconfounding/notebooks/checkpoints/train_vae_uot-epoch=21285-val_loss=48.59.ckpt as vae_uot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train_vae_uot-epoch=21285-val_loss=48.59.ckpt: 100%|██████████| 43/43 [00:00<00:00, 613.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for vae_uot:\n",
      "  batch_entropy: 0.6931471824645996\n",
      "  ilisi_batch: 2.0\n",
      "  clisi_celltype: 1.2195122241973877\n",
      "  silhouette_score: -0.011280431412160397\n",
      "  normalized_mutual_info: 0.00041299566030934126\n"
     ]
    }
   ],
   "source": [
    "# Map checkpoint names to model classes (adjust as needed)\n",
    "model_map = {\n",
    "    \"vae-\": VAE,\n",
    "    \"vae_uot\": VAE_OT,\n",
    "    \"vae_d\": VAEDiscriminator,\n",
    "    \"vae_c\": VAEWasserstein,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ckpt_path in ckpt_files:\n",
    "    # Guess model type from filename\n",
    "    for key, model_class in model_map.items():\n",
    "        if key in os.path.basename(ckpt_path).lower():\n",
    "            print(f\"Evaluating checkpoint {ckpt_path} as {key}\")\n",
    "            embeddings, batches, cell_type, metrics_dict = load_and_eval(\n",
    "                model_class, ckpt_path, config, test_loader\n",
    "            )\n",
    "            results[key] = {\n",
    "                \"embeddings\": embeddings,\n",
    "                \"batches\": batches,\n",
    "                \"cell_type\": cell_type,\n",
    "                \"metrics\": metrics_dict,\n",
    "            }\n",
    "            print(f\"Metrics for {key}:\")\n",
    "            for k, v in metrics_dict.items():\n",
    "                print(f\"  {k}: {v}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: UMAP visualization for each model\n",
    "for key, res in results.items():\n",
    "    embeddings_np = res[\"embeddings\"].numpy()\n",
    "    batches_np = res[\"batches\"].argmax(dim=1).numpy()\n",
    "    cell_type_np = res[\"cell_type\"].argmax(dim=1).numpy()\n",
    "\n",
    "    umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding_2d = umap_model.fit_transform(embeddings_np)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=embedding_2d[:, 0], y=embedding_2d[:, 1], hue=batches_np, palette=\"tab10\", s=10)\n",
    "    plt.title(f\"UMAP by Batch ({key})\")\n",
    "    plt.legend(title=\"Batch\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=embedding_2d[:, 0], y=embedding_2d[:, 1], hue=cell_type_np, palette=\"tab20\", s=10)\n",
    "    plt.title(f\"UMAP by Cell Type ({key})\")\n",
    "    plt.legend(title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
