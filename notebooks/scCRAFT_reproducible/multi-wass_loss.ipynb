{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import wcd_vae\n",
    "from wcd_vae.scCRAFT.model import train_integration_model, obtain_embeddings\n",
    "from wcd_vae.scCRAFT.utils import multi_resolution_cluster\n",
    "import scvi\n",
    "import scib \n",
    "import harmonypy as hm\n",
    "import pandas as pd\n",
    "import scanorama\n",
    "import time\n",
    "import bbknn\n",
    "import scDML\n",
    "import imap\n",
    "from scib.utils import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap_by_technology(adata, batch_key='tech', color_key='celltype', ncols=3, figsize_per_panel=(5, 5)):\n",
    "    \"\"\"\n",
    "    Plot UMAP with consistent x and y scales and consistent colors for each technology/batch.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Annotated data object with UMAP coordinates in obsm['X_umap']\n",
    "    batch_key : str, default 'tech'\n",
    "        Key in adata.obs containing batch/technology information\n",
    "    color_key : str, default 'celltype'\n",
    "        Key in adata.obs for coloring points\n",
    "    ncols : int, default 3\n",
    "        Maximum number of columns in subplot grid\n",
    "    figsize_per_panel : tuple, default (5, 5)\n",
    "        Size of each subplot panel\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None (displays plots)\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import scanpy as sc\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    sc.tl.umap(adata, min_dist=0.5)\n",
    "    \n",
    "    # Ensure cell types are categorical\n",
    "    if not pd.api.types.is_categorical_dtype(adata.obs[color_key]):\n",
    "        adata.obs[color_key] = adata.obs[color_key].astype('category')\n",
    "    \n",
    "    # Get unique technologies/batches and cell types\n",
    "    technologies = adata.obs[batch_key].unique()\n",
    "    cell_types = adata.obs[color_key].cat.categories\n",
    "    \n",
    "    # Create a consistent colormap for cell types\n",
    "    cmap = plt.cm.get_cmap('tab20', len(cell_types))\n",
    "    colors = [cmap(i) for i in range(len(cell_types))]\n",
    "    color_dict = dict(zip(cell_types, colors))\n",
    "    \n",
    "    # Get the overall x and y limits from the full UMAP\n",
    "    x_coords = adata.obsm['X_umap'][:, 0]\n",
    "    y_coords = adata.obsm['X_umap'][:, 1]\n",
    "    x_min, x_max = x_coords.min() - 0.5, x_coords.max() + 0.5\n",
    "    y_min, y_max = y_coords.min() - 0.5, y_coords.max() + 0.5\n",
    "    \n",
    "    # Create subplots - adjust the number of columns based on preference\n",
    "    n_techs = len(technologies)\n",
    "    ncols = min(ncols, n_techs)\n",
    "    nrows = (n_techs + ncols - 1) // ncols\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(figsize_per_panel[0]*ncols, figsize_per_panel[1]*nrows))\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = [axes]\n",
    "    elif nrows == 1 or ncols == 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    # Plot each technology separately\n",
    "    for i, tech in enumerate(technologies):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Subset data for this technology\n",
    "        tech_mask = adata.obs[batch_key] == tech\n",
    "        tech_coords = adata.obsm['X_umap'][tech_mask]\n",
    "        tech_celltypes = adata.obs.loc[tech_mask, color_key]\n",
    "        \n",
    "        # Plot each cell type with consistent colors\n",
    "        for cell_type in cell_types:\n",
    "            cell_mask = tech_celltypes == cell_type\n",
    "            if np.sum(cell_mask) > 0:  # Only plot if there are cells of this type\n",
    "                ax.scatter(\n",
    "                    tech_coords[cell_mask, 0], \n",
    "                    tech_coords[cell_mask, 1],\n",
    "                    color=color_dict[cell_type],\n",
    "                    s=1, alpha=0.7, label=cell_type\n",
    "                )\n",
    "        \n",
    "        # Set consistent limits for all subplots\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('UMAP1')\n",
    "        ax.set_ylabel('UMAP2')\n",
    "        ax.set_title(f'{batch_key.capitalize()}: {tech}')\n",
    "        ax.set_aspect('equal')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(n_techs, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    # Add a legend to the figure (outside the plots)\n",
    "    handles, labels = [], []\n",
    "    for cell_type in cell_types:\n",
    "        handles.append(plt.Line2D([0], [0], marker='o', color=color_dict[cell_type], \n",
    "                                 label=cell_type, markersize=5, linestyle='None'))\n",
    "        labels.append(cell_type)\n",
    "    \n",
    "    fig.legend(handles, labels, loc='center right', bbox_to_anchor=(1.15, 0.5))\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make room for legend\n",
    "    plt.show()\n",
    "    \n",
    "    # Also create a combined plot with all technologies\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharex=True, sharey=True)\n",
    "    \n",
    "    # Plot colored by technology/batch\n",
    "    sc.pl.umap(adata, color=batch_key, ax=ax1, frameon=False, show=False)\n",
    "    ax1.set_xlim(x_min, x_max)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    ax1.set_title(f'Colored by {batch_key.capitalize()}')\n",
    "    \n",
    "    # Plot colored by celltype with consistent colors\n",
    "    for cell_type in cell_types:\n",
    "        cell_mask = adata.obs[color_key] == cell_type\n",
    "        if np.sum(cell_mask) > 0:\n",
    "            ax2.scatter(\n",
    "                adata.obsm['X_umap'][cell_mask, 0],\n",
    "                adata.obsm['X_umap'][cell_mask, 1],\n",
    "                color=color_dict[cell_type],\n",
    "                s=1, alpha=0.7, label=cell_type\n",
    "            )\n",
    "    \n",
    "    ax2.set_xlim(x_min, x_max)\n",
    "    ax2.set_ylim(y_min, y_max)\n",
    "    ax2.set_title(f'Colored by {color_key.capitalize()}')\n",
    "    \n",
    "    # Add legend to the second plot\n",
    "    handles, labels = [], []\n",
    "    for cell_type in cell_types:\n",
    "        handles.append(plt.Line2D([0], [0], marker='o', color=color_dict[cell_type], \n",
    "                                 label=cell_type, markersize=5, linestyle='None'))\n",
    "        labels.append(cell_type)\n",
    "    \n",
    "    fig.legend(handles, labels, loc='center right', bbox_to_anchor=(1.15, 0.5))\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make room for legend\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import entropy\n",
    "import scanpy as sc\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_lisi(X, metadata, label_colname, perplexity=30):\n",
    "    \"\"\"\n",
    "    Compute Local Inverse Simpson Index (LISI) for batch mixing evaluation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        The embedded data matrix\n",
    "    metadata : pandas.DataFrame\n",
    "        Metadata containing batch/label information\n",
    "    label_colname : str\n",
    "        Column name in metadata containing the batch labels\n",
    "    perplexity : int, default=30\n",
    "        Perplexity parameter for Gaussian kernel (similar to t-SNE)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    lisi_scores : array-like\n",
    "        LISI score for each cell\n",
    "    \"\"\"\n",
    "    n_cells = X.shape[0]\n",
    "    \n",
    "    # Get batch labels\n",
    "    batch_labels = metadata[label_colname].values\n",
    "    unique_batches = np.unique(batch_labels)\n",
    "    n_batches = len(unique_batches)\n",
    "    \n",
    "    # Create mapping from batch to index\n",
    "    batch_to_idx = {batch: idx for idx, batch in enumerate(unique_batches)}\n",
    "    batch_indices = np.array([batch_to_idx[batch] for batch in batch_labels])\n",
    "    \n",
    "    # Find k-nearest neighbors (k should be larger than perplexity)\n",
    "    k = min(90, n_cells - 1)  # Use 90 neighbors or n_cells-1 if smaller\n",
    "    print(f\"Computing {k} nearest neighbors for {n_cells} cells...\")\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    \n",
    "    lisi_scores = np.zeros(n_cells)\n",
    "    \n",
    "    # Add progress bar for LISI computation\n",
    "    print(f\"Computing LISI scores for {label_colname}...\")\n",
    "    for i in tqdm(range(n_cells), desc=\"Computing LISI\"):\n",
    "        # Get neighbors and distances for current cell\n",
    "        neighbor_indices = indices[i, 1:]  # Exclude self (index 0)\n",
    "        neighbor_distances = distances[i, 1:]\n",
    "        \n",
    "        # Compute Gaussian kernel weights with adaptive bandwidth\n",
    "        # Find bandwidth that gives desired perplexity\n",
    "        sigma = find_sigma(neighbor_distances, perplexity)\n",
    "        weights = np.exp(-neighbor_distances**2 / (2 * sigma**2))\n",
    "        weights = weights / np.sum(weights)  # Normalize\n",
    "        \n",
    "        # Get batch labels of neighbors\n",
    "        neighbor_batches = batch_indices[neighbor_indices]\n",
    "        \n",
    "        # Compute probability of each batch in neighborhood\n",
    "        batch_probs = np.zeros(n_batches)\n",
    "        for j, batch_idx in enumerate(neighbor_batches):\n",
    "            batch_probs[batch_idx] += weights[j]\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        batch_probs = batch_probs + 1e-12\n",
    "        \n",
    "        # Compute Simpson diversity (inverse Simpson index)\n",
    "        simpson_index = np.sum(batch_probs**2)\n",
    "        lisi_scores[i] = 1.0 / simpson_index\n",
    "    \n",
    "    return lisi_scores\n",
    "\n",
    "def find_sigma(distances, target_perplexity, tol=1e-5, max_iter=50):\n",
    "    \"\"\"\n",
    "    Find the Gaussian kernel bandwidth (sigma) that achieves target perplexity.\n",
    "    Uses binary search similar to t-SNE implementation.\n",
    "    \"\"\"\n",
    "    def perplexity_fn(sigma):\n",
    "        if sigma <= 0:\n",
    "            return 0\n",
    "        weights = np.exp(-distances**2 / (2 * sigma**2))\n",
    "        weights = weights / np.sum(weights)\n",
    "        # Avoid log(0)\n",
    "        weights = np.maximum(weights, 1e-12)\n",
    "        H = -np.sum(weights * np.log2(weights))\n",
    "        return 2**H\n",
    "    \n",
    "    # Binary search for sigma\n",
    "    sigma_min, sigma_max = 1e-20, 1000.0\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        sigma = (sigma_min + sigma_max) / 2.0\n",
    "        perp = perplexity_fn(sigma)\n",
    "        \n",
    "        if abs(perp - target_perplexity) < tol:\n",
    "            break\n",
    "            \n",
    "        if perp > target_perplexity:\n",
    "            sigma_max = sigma\n",
    "        else:\n",
    "            sigma_min = sigma\n",
    "    \n",
    "    return sigma\n",
    "\n",
    "def ilisi_graph(adata, batch_key, type=\"embed\", use_rep=\"X_pca\", perplexity=30):\n",
    "    \"\"\"\n",
    "    Compute integration Local Inverse Simpson Index (iLISI) for an AnnData object.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Annotated data object\n",
    "    batch_key : str\n",
    "        Key in adata.obs containing batch information\n",
    "    type : str, default=\"embed\"\n",
    "        Type of data to use (\"embed\" for embeddings)\n",
    "    use_rep : str, default=\"X_pca\"\n",
    "        Key in adata.obsm for the embedding to use\n",
    "    perplexity : int, default=30\n",
    "        Perplexity parameter for neighborhood definition\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Normalized mean iLISI score across all cells (0-1 range)\n",
    "    \"\"\"\n",
    "    if type == \"embed\":\n",
    "        print(\"Using embed\")\n",
    "        if use_rep not in adata.obsm:\n",
    "            raise ValueError(f\"Embedding {use_rep} not found in adata.obsm\")\n",
    "        X = adata.obsm[use_rep]\n",
    "    else:\n",
    "        X = adata.X\n",
    "    \n",
    "    if batch_key not in adata.obs:\n",
    "        raise ValueError(f\"Batch key {batch_key} not found in adata.obs\")\n",
    "    \n",
    "    # Get number of unique batches for normalization\n",
    "    n_batches = len(adata.obs[batch_key].unique())\n",
    "    \n",
    "    # Compute LISI scores\n",
    "    print(\"Computing LISI\")\n",
    "    lisi_scores = compute_lisi(X, adata.obs, batch_key, perplexity)\n",
    "    \n",
    "    # Normalize by number of batches (perfect mixing = 1.0, no mixing = 1/n_batches)\n",
    "    normalized_scores = (lisi_scores - 1) / (n_batches - 1)\n",
    "    \n",
    "    # Return mean normalized iLISI score\n",
    "    return np.mean(normalized_scores)\n",
    "\n",
    "def clisi_graph(adata, label_key, type=\"embed\", use_rep=\"X_pca\", perplexity=30):\n",
    "    \"\"\"\n",
    "    Compute cell-type Local Inverse Simpson Index (cLISI) for an AnnData object.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Annotated data object\n",
    "    label_key : str\n",
    "        Key in adata.obs containing cell type information\n",
    "    type : str, default=\"embed\"\n",
    "        Type of data to use (\"embed\" for embeddings)\n",
    "    use_rep : str, default=\"X_pca\"\n",
    "        Key in adata.obsm for the embedding to use\n",
    "    perplexity : int, default=30\n",
    "        Perplexity parameter for neighborhood definition\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Normalized mean cLISI score across all cells (0-1 range)\n",
    "    \"\"\"\n",
    "    if type == \"embed\":\n",
    "        print(\"Using embed\")\n",
    "        if use_rep not in adata.obsm:\n",
    "            raise ValueError(f\"Embedding {use_rep} not found in adata.obsm\")\n",
    "        X = adata.obsm[use_rep]\n",
    "    else:\n",
    "        X = adata.X\n",
    "    \n",
    "    if label_key not in adata.obs:\n",
    "        raise ValueError(f\"Label key {label_key} not found in adata.obs\")\n",
    "    \n",
    "    # Get number of unique cell types for normalization\n",
    "    n_celltypes = len(adata.obs[label_key].unique())\n",
    "    \n",
    "    print(\"Computing LISI\")\n",
    "    # Compute LISI scores\n",
    "    lisi_scores = compute_lisi(X, adata.obs, label_key, perplexity)\n",
    "    \n",
    "    # Normalize by number of cell types (perfect mixing = 1.0, no mixing = 1/n_celltypes)\n",
    "    normalized_scores = (lisi_scores - 1) / (n_celltypes - 1)\n",
    "    \n",
    "    # Return mean normalized cLISI score\n",
    "    return np.mean(normalized_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the torch random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"/workspaces/data/human_pancreas_norm_complexBatch.h5ad\")\n",
    "\n",
    "adata.raw = adata\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "sc.pp.filter_cells(adata, min_genes=300)\n",
    "sc.pp.filter_genes(adata, min_cells=5)\n",
    "sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000, batch_key='tech')\n",
    "adata = adata[:, adata.var['highly_variable']]\n",
    "multi_resolution_cluster(adata, resolution1 = 1, method = 'Leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_by_technology(adata, batch_key='tech', color_key='celltype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = train_integration_model(adata, batch_key = 'tech', z_dim=256, d_coef = 0.01, epochs=100, critic=True, disc_iter=10)\n",
    "obtain_embeddings(adata, VAE.to(\"cuda:0\"))\n",
    "sc.pp.neighbors(adata, use_rep=\"X_scCRAFT\")\n",
    "plot_umap_by_technology(adata, batch_key='tech', color_key='celltype')\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "\n",
    "ilisi_score = ilisi_graph(adata, batch_key=\"tech\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"iLISI score (1 is best): {ilisi_score:.4f}\")\n",
    "\n",
    "clisi_score = clisi_graph(adata, label_key=\"celltype\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"cLISI score (0 is best): {clisi_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = train_integration_model(adata, batch_key = 'tech', z_dim=256, d_coef = 0.4, epochs=100, critic=True, disc_iter=10)\n",
    "obtain_embeddings(adata, VAE.to(\"cuda:0\"))\n",
    "sc.pp.neighbors(adata, use_rep=\"X_scCRAFT\")\n",
    "plot_umap_by_technology(adata, batch_key='tech', color_key='celltype')\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "\n",
    "ilisi_score = ilisi_graph(adata, batch_key=\"tech\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"iLISI score (1 is best): {ilisi_score:.4f}\")\n",
    "\n",
    "clisi_score = clisi_graph(adata, label_key=\"celltype\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"cLISI score (0 is best): {clisi_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = train_integration_model(adata, batch_key = 'tech', z_dim=256, d_coef = 0.1, epochs=100, critic=False, disc_iter=1)\n",
    "obtain_embeddings(adata, VAE.to(\"cuda:0\"))\n",
    "sc.pp.neighbors(adata, use_rep=\"X_scCRAFT\")\n",
    "sc.tl.umap(adata, min_dist=0.5)\n",
    "sc.pl.umap(adata, color=[\"tech\", \"celltype\"], frameon=False, ncols=1)\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "\n",
    "ilisi_score = ilisi_graph(adata, batch_key=\"tech\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"iLISI score (1 is best): {ilisi_score:.4f}\")\n",
    "\n",
    "clisi_score = clisi_graph(adata, label_key=\"celltype\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"cLISI score (0 is best): {clisi_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scVI\n",
    "adata = adata.copy()\n",
    "adata.layers['counts'] = adata.X\n",
    "scvi.model.SCVI.setup_anndata(adata, layer=\"counts\", batch_key=\"tech\") \n",
    "vae = scvi.model.SCVI(adata, n_layers=2, n_latent=50, gene_likelihood=\"nb\")\n",
    "vae.train()\n",
    "adata.obsm[\"X_scVI\"] = vae.get_latent_representation()\n",
    "sc.pp.neighbors(adata, use_rep=\"X_scVI\")\n",
    "sc.tl.umap(adata, min_dist=0.5)\n",
    "sc.pl.umap(adata, color=[\"tech\", \"celltype\"], frameon=False, ncols=1)\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmony\n",
    "sc.tl.pca(adata, n_comps=50)\n",
    "data_mat = adata.obsm['X_pca']\n",
    "meta_data = adata.obs\n",
    "\n",
    "# Specify the variables to use (as in your original code)\n",
    "vars_use = ['tech']\n",
    "\n",
    "# Run Harmony\n",
    "start_time = time.time() \n",
    "ho = hm.run_harmony(data_mat, meta_data, vars_use)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Convert the adjusted PCs to a DataFrame\n",
    "res = pd.DataFrame(ho.Z_corr)\n",
    "res.columns = ['X{}'.format(i + 1) for i in range(res.shape[1])]\n",
    "\n",
    "# If you want to store the adjusted PCs back into the AnnData object\n",
    "adata.obsm['X_harmony'] = res.values.T\n",
    "sc.pp.neighbors(adata, use_rep=\"X_harmony\")\n",
    "sc.tl.umap(adata, min_dist=0.5)\n",
    "sc.pl.umap(adata, color=[\"tech\", \"celltype\"], frameon=False, ncols=1)\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scanorama\n",
    "# Save original order of cells\n",
    "original_order = adata.obs_names.copy()\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Your existing Scanorama correction process\n",
    "split, categories = split_batches(adata.copy(), 'batch', return_categories=True)\n",
    "corrected = scanorama.correct_scanpy(split, return_dimred=True)\n",
    "corrected = anndata.AnnData.concatenate(\n",
    "    *corrected, batch_key='batch', batch_categories=categories, index_unique=None\n",
    ")\n",
    "\n",
    "# Reorder corrected data to match original order\n",
    "corrected = corrected[original_order]\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Replace adata with corrected data\n",
    "adatas = corrected.copy()\n",
    "\n",
    "adata.obsm['X_scanorama'] = adatas.obsm['X_scanorama']\n",
    "\n",
    "# Proceed with your analysis (neighbors, UMAP, plotting)\n",
    "sc.pp.neighbors(adata, n_pcs=30, use_rep=\"X_scanorama\")\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=[\"batch\", \"cell_type\"], frameon=False, ncols=1)\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() \n",
    "bbknn.bbknn(adata, batch_key='batch')\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "sc.tl.umap(adata, min_dist=0.5)\n",
    "sc.pl.umap(adata, color=[\"batch\", \"cell_type\"], frameon=False, ncols=1)\n",
    "adata.obsm['X_bbknn'] = adata.obsm['X_umap']\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iMAP\n",
    "\n",
    "if type(adata.X) != type(np.array([])):\n",
    "    adata.X = adata.X.toarray()\n",
    "start_time = time.time() \n",
    "### Stage I\n",
    "print('HI')\n",
    "EC, ec_data = imap.stage1.iMAP_fast(adata, key='batch', n_epochs=50)\n",
    "### Stage II\n",
    "output_results = imap.stage2.integrate_data(adata, ec_data, key='batch', n_epochs=40)\n",
    "output_results.shape\n",
    "end_time = time.time()\n",
    "print('total time talken', end_time-start_time)\n",
    "adata_int = adata.copy()\n",
    "adata_int.X = output_results\n",
    "\n",
    "sc.tl.pca(adata_int, n_comps=50)\n",
    "sc.pp.neighbors(adata_int, use_rep=\"X_pca\")\n",
    "sc.tl.umap(adata_int, min_dist=0.5)\n",
    "sc.pl.umap(adata_int, color=[\"batch\", \"cell_type\"], frameon=False, ncols=1)\n",
    "adata.obsm['imap'] = adata_int.obsm['X_pca']\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scDML\n",
    "\n",
    "start_time = time.time()\n",
    "ncluster = len(adata.obs['cell_type'].unique())\n",
    "scdml=scDMLModel()\n",
    "adata_int = adata.copy()\n",
    "adata_int=scdml.preprocess(adata_int, cluster_method=\"louvain\",resolution=3.0,batch_key = 'batch')\n",
    "scdml.integrate(adata_int,batch_key='batch',ncluster_list=[ncluster],\n",
    "               expect_num_cluster=ncluster,merge_rule=\"rule2\", out_dim=50)\n",
    "end_time = time.time()\n",
    "print('time taken to run :', end_time - start_time)\n",
    "adata.obsm['scDML'] = adata_int.obsm['X_emb']\n",
    "sc.pp.neighbors(adata, use_rep='scDML')\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=[\"batch\", \"cell_type\"], frameon=False, ncols=1)\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seurat R pipeline\n",
    "```R\n",
    "library(Seurat)\n",
    "library(anndata)\n",
    "library(reticulate)\n",
    "library(SeuratWrappers)\n",
    "library(SeuratDisk)\n",
    "\n",
    "Convert('/path/Lung_atlas_raw.h5ad', \"h5seurat\", assay = \"RNA\",\n",
    "        overwrite = T, verbose = T)\n",
    "seurat_obj <- LoadH5Seurat(\"/path/Lung_atlas_raw.h5seurat\", assay = \"RNA\", meta.data = T)\n",
    "saveRDS(seurat_obj, file = \"/path/Lung_atlas_raw.rds\")  \n",
    "\n",
    "seurat_obj = readRDS(\"/path/Lung_atlas_raw.rds\")\n",
    "original_cell_order <- colnames(seurat_obj@assays$RNA@counts)\n",
    "seurat_obj[[\"RNA\"]] <- split(seurat_obj[[\"RNA\"]], f = seurat_obj$batch)\n",
    "seurat_obj <- SCTransform(seurat_obj)\n",
    "seurat_obj <- RunPCA(seurat_obj, npcs = 50, verbose = F)\n",
    "seurat_obj <- IntegrateLayers(\n",
    "  object = seurat_obj, method = RPCAIntegration,\n",
    "  new.reduction = \"integrated.rpca\", normalization.method = \"SCT\",\n",
    "  verbose = FALSE\n",
    ")\n",
    "\n",
    "integrated_rpca_embeddings <- Embeddings(object = seurat_obj, reduction = \"integrated.rpca\")\n",
    "pca_embeddings <- integrated_rpca_embeddings[, 1:50]\n",
    "pca_embeddings_ordered <- pca_embeddings[match(original_cell_order, rownames(pca_embeddings)), ]\n",
    "write.csv(pca_embeddings_ordered, file = \"/path/Lung_atlas_seurat.csv\", row.names = TRUE)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_embeddings = pd.read_csv('/path/Lung_atlas_seurat.csv', index_col=0)\n",
    "adata.obsm['X_seurat'] = pca_embeddings.values\n",
    "sc.pp.neighbors(adata, use_rep=\"X_seurat\")\n",
    "sc.tl.umap(adata, min_dist=0.5)\n",
    "sc.pl.umap(adata, color=[\"batch\", \"cell_type\"], frameon=False, ncols=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Questions?\n",
    "- How consistent is the Critic vs discriminator?\n",
    "- Which cell types collapse first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
