{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import wcd_vae\n",
    "from wcd_vae.scCRAFT.model import train_integration_model, obtain_embeddings\n",
    "from wcd_vae.scCRAFT.utils import multi_resolution_cluster\n",
    "import scvi\n",
    "import scib \n",
    "import harmonypy as hm\n",
    "import pandas as pd\n",
    "import scanorama\n",
    "import time\n",
    "import bbknn\n",
    "import scDML\n",
    "import imap\n",
    "from scib.utils import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap_by_technology(adata, batch_key='tech', color_key='celltype', ncols=3, figsize_per_panel=(5, 5)):\n",
    "    \"\"\"\n",
    "    Plot UMAP with consistent x and y scales and consistent colors for each technology/batch.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Annotated data object with UMAP coordinates in obsm['X_umap']\n",
    "    batch_key : str, default 'tech'\n",
    "        Key in adata.obs containing batch/technology information\n",
    "    color_key : str, default 'celltype'\n",
    "        Key in adata.obs for coloring points\n",
    "    ncols : int, default 3\n",
    "        Maximum number of columns in subplot grid\n",
    "    figsize_per_panel : tuple, default (5, 5)\n",
    "        Size of each subplot panel\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None (displays plots)\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import scanpy as sc\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    sc.tl.umap(adata, min_dist=0.5)\n",
    "    \n",
    "    # Ensure cell types are categorical\n",
    "    if not pd.api.types.is_categorical_dtype(adata.obs[color_key]):\n",
    "        adata.obs[color_key] = adata.obs[color_key].astype('category')\n",
    "    \n",
    "    # Get unique technologies/batches and cell types\n",
    "    technologies = adata.obs[batch_key].unique()\n",
    "    cell_types = adata.obs[color_key].cat.categories\n",
    "    \n",
    "    # Create a consistent colormap for cell types\n",
    "    cmap = plt.cm.get_cmap('tab20', len(cell_types))\n",
    "    colors = [cmap(i) for i in range(len(cell_types))]\n",
    "    color_dict = dict(zip(cell_types, colors))\n",
    "    \n",
    "    # Get the overall x and y limits from the full UMAP\n",
    "    x_coords = adata.obsm['X_umap'][:, 0]\n",
    "    y_coords = adata.obsm['X_umap'][:, 1]\n",
    "    x_min, x_max = x_coords.min() - 0.5, x_coords.max() + 0.5\n",
    "    y_min, y_max = y_coords.min() - 0.5, y_coords.max() + 0.5\n",
    "    \n",
    "    # Create subplots - adjust the number of columns based on preference\n",
    "    n_techs = len(technologies)\n",
    "    ncols = min(ncols, n_techs)\n",
    "    nrows = (n_techs + ncols - 1) // ncols\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(figsize_per_panel[0]*ncols, figsize_per_panel[1]*nrows))\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = [axes]\n",
    "    elif nrows == 1 or ncols == 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    # Plot each technology separately\n",
    "    for i, tech in enumerate(technologies):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Subset data for this technology\n",
    "        tech_mask = adata.obs[batch_key] == tech\n",
    "        tech_coords = adata.obsm['X_umap'][tech_mask]\n",
    "        tech_celltypes = adata.obs.loc[tech_mask, color_key]\n",
    "        \n",
    "        # Plot each cell type with consistent colors\n",
    "        for cell_type in cell_types:\n",
    "            cell_mask = tech_celltypes == cell_type\n",
    "            if np.sum(cell_mask) > 0:  # Only plot if there are cells of this type\n",
    "                ax.scatter(\n",
    "                    tech_coords[cell_mask, 0], \n",
    "                    tech_coords[cell_mask, 1],\n",
    "                    color=color_dict[cell_type],\n",
    "                    s=1, alpha=0.7, label=cell_type\n",
    "                )\n",
    "        \n",
    "        # Set consistent limits for all subplots\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('UMAP1')\n",
    "        ax.set_ylabel('UMAP2')\n",
    "        ax.set_title(f'{batch_key.capitalize()}: {tech}')\n",
    "        ax.set_aspect('equal')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(n_techs, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    # Add a legend to the figure (outside the plots)\n",
    "    handles, labels = [], []\n",
    "    for cell_type in cell_types:\n",
    "        handles.append(plt.Line2D([0], [0], marker='o', color=color_dict[cell_type], \n",
    "                                 label=cell_type, markersize=5, linestyle='None'))\n",
    "        labels.append(cell_type)\n",
    "    \n",
    "    fig.legend(handles, labels, loc='center right', bbox_to_anchor=(1.15, 0.5))\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make room for legend\n",
    "    plt.show()\n",
    "    \n",
    "    # Also create a combined plot with all technologies\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharex=True, sharey=True)\n",
    "    \n",
    "    # Plot colored by technology/batch\n",
    "    sc.pl.umap(adata, color=batch_key, ax=ax1, frameon=False, show=False)\n",
    "    ax1.set_xlim(x_min, x_max)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    ax1.set_title(f'Colored by {batch_key.capitalize()}')\n",
    "    \n",
    "    # Plot colored by celltype with consistent colors\n",
    "    for cell_type in cell_types:\n",
    "        cell_mask = adata.obs[color_key] == cell_type\n",
    "        if np.sum(cell_mask) > 0:\n",
    "            ax2.scatter(\n",
    "                adata.obsm['X_umap'][cell_mask, 0],\n",
    "                adata.obsm['X_umap'][cell_mask, 1],\n",
    "                color=color_dict[cell_type],\n",
    "                s=1, alpha=0.7, label=cell_type\n",
    "            )\n",
    "    \n",
    "    ax2.set_xlim(x_min, x_max)\n",
    "    ax2.set_ylim(y_min, y_max)\n",
    "    ax2.set_title(f'Colored by {color_key.capitalize()}')\n",
    "    \n",
    "    # Add legend to the second plot\n",
    "    handles, labels = [], []\n",
    "    for cell_type in cell_types:\n",
    "        handles.append(plt.Line2D([0], [0], marker='o', color=color_dict[cell_type], \n",
    "                                 label=cell_type, markersize=5, linestyle='None'))\n",
    "        labels.append(cell_type)\n",
    "    \n",
    "    fig.legend(handles, labels, loc='center right', bbox_to_anchor=(1.15, 0.5))\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make room for legend\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import entropy\n",
    "import scanpy as sc\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_lisi(X, metadata, label_colname, perplexity=30):\n",
    "    \"\"\"\n",
    "    Compute Local Inverse Simpson Index (LISI) for batch mixing evaluation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        The embedded data matrix\n",
    "    metadata : pandas.DataFrame\n",
    "        Metadata containing batch/label information\n",
    "    label_colname : str\n",
    "        Column name in metadata containing the batch labels\n",
    "    perplexity : int, default=30\n",
    "        Perplexity parameter for Gaussian kernel (similar to t-SNE)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    lisi_scores : array-like\n",
    "        LISI score for each cell\n",
    "    \"\"\"\n",
    "    n_cells = X.shape[0]\n",
    "    \n",
    "    # Get batch labels\n",
    "    batch_labels = metadata[label_colname].values\n",
    "    unique_batches = np.unique(batch_labels)\n",
    "    n_batches = len(unique_batches)\n",
    "    \n",
    "    # Create mapping from batch to index\n",
    "    batch_to_idx = {batch: idx for idx, batch in enumerate(unique_batches)}\n",
    "    batch_indices = np.array([batch_to_idx[batch] for batch in batch_labels])\n",
    "    \n",
    "    # Find k-nearest neighbors (k should be larger than perplexity)\n",
    "    k = min(90, n_cells - 1)  # Use 90 neighbors or n_cells-1 if smaller\n",
    "    print(f\"Computing {k} nearest neighbors for {n_cells} cells...\")\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    \n",
    "    lisi_scores = np.zeros(n_cells)\n",
    "    \n",
    "    # Add progress bar for LISI computation\n",
    "    print(f\"Computing LISI scores for {label_colname}...\")\n",
    "    for i in tqdm(range(n_cells), desc=\"Computing LISI\"):\n",
    "        # Get neighbors and distances for current cell\n",
    "        neighbor_indices = indices[i, 1:]  # Exclude self (index 0)\n",
    "        neighbor_distances = distances[i, 1:]\n",
    "        \n",
    "        # Compute Gaussian kernel weights with adaptive bandwidth\n",
    "        # Find bandwidth that gives desired perplexity\n",
    "        sigma = find_sigma(neighbor_distances, perplexity)\n",
    "        weights = np.exp(-neighbor_distances**2 / (2 * sigma**2))\n",
    "        weights = weights / np.sum(weights)  # Normalize\n",
    "        \n",
    "        # Get batch labels of neighbors\n",
    "        neighbor_batches = batch_indices[neighbor_indices]\n",
    "        \n",
    "        # Compute probability of each batch in neighborhood\n",
    "        batch_probs = np.zeros(n_batches)\n",
    "        for j, batch_idx in enumerate(neighbor_batches):\n",
    "            batch_probs[batch_idx] += weights[j]\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        batch_probs = batch_probs + 1e-12\n",
    "        \n",
    "        # Compute Simpson diversity (inverse Simpson index)\n",
    "        simpson_index = np.sum(batch_probs**2)\n",
    "        lisi_scores[i] = 1.0 / simpson_index\n",
    "    \n",
    "    return lisi_scores\n",
    "\n",
    "def find_sigma(distances, target_perplexity, tol=1e-5, max_iter=50):\n",
    "    \"\"\"\n",
    "    Find the Gaussian kernel bandwidth (sigma) that achieves target perplexity.\n",
    "    Uses binary search similar to t-SNE implementation.\n",
    "    \"\"\"\n",
    "    def perplexity_fn(sigma):\n",
    "        if sigma <= 0:\n",
    "            return 0\n",
    "        weights = np.exp(-distances**2 / (2 * sigma**2))\n",
    "        weights = weights / np.sum(weights)\n",
    "        # Avoid log(0)\n",
    "        weights = np.maximum(weights, 1e-12)\n",
    "        H = -np.sum(weights * np.log2(weights))\n",
    "        return 2**H\n",
    "    \n",
    "    # Binary search for sigma\n",
    "    sigma_min, sigma_max = 1e-20, 1000.0\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        sigma = (sigma_min + sigma_max) / 2.0\n",
    "        perp = perplexity_fn(sigma)\n",
    "        \n",
    "        if abs(perp - target_perplexity) < tol:\n",
    "            break\n",
    "            \n",
    "        if perp > target_perplexity:\n",
    "            sigma_max = sigma\n",
    "        else:\n",
    "            sigma_min = sigma\n",
    "    \n",
    "    return sigma\n",
    "\n",
    "def ilisi_graph(adata, batch_key, type=\"embed\", use_rep=\"X_pca\", perplexity=30):\n",
    "    \"\"\"\n",
    "    Compute integration Local Inverse Simpson Index (iLISI) for an AnnData object.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Annotated data object\n",
    "    batch_key : str\n",
    "        Key in adata.obs containing batch information\n",
    "    type : str, default=\"embed\"\n",
    "        Type of data to use (\"embed\" for embeddings)\n",
    "    use_rep : str, default=\"X_pca\"\n",
    "        Key in adata.obsm for the embedding to use\n",
    "    perplexity : int, default=30\n",
    "        Perplexity parameter for neighborhood definition\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Normalized mean iLISI score across all cells (0-1 range)\n",
    "    \"\"\"\n",
    "    if type == \"embed\":\n",
    "        print(\"Using embed\")\n",
    "        if use_rep not in adata.obsm:\n",
    "            raise ValueError(f\"Embedding {use_rep} not found in adata.obsm\")\n",
    "        X = adata.obsm[use_rep]\n",
    "    else:\n",
    "        X = adata.X\n",
    "    \n",
    "    if batch_key not in adata.obs:\n",
    "        raise ValueError(f\"Batch key {batch_key} not found in adata.obs\")\n",
    "    \n",
    "    # Get number of unique batches for normalization\n",
    "    n_batches = len(adata.obs[batch_key].unique())\n",
    "    \n",
    "    # Compute LISI scores\n",
    "    print(\"Computing LISI\")\n",
    "    lisi_scores = compute_lisi(X, adata.obs, batch_key, perplexity)\n",
    "    \n",
    "    # Normalize by number of batches (perfect mixing = 1.0, no mixing = 1/n_batches)\n",
    "    normalized_scores = (lisi_scores - 1) / (n_batches - 1)\n",
    "    \n",
    "    # Return mean normalized iLISI score\n",
    "    return np.mean(normalized_scores)\n",
    "\n",
    "def clisi_graph(adata, label_key, type=\"embed\", use_rep=\"X_pca\", perplexity=30):\n",
    "    \"\"\"\n",
    "    Compute cell-type Local Inverse Simpson Index (cLISI) for an AnnData object.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Annotated data object\n",
    "    label_key : str\n",
    "        Key in adata.obs containing cell type information\n",
    "    type : str, default=\"embed\"\n",
    "        Type of data to use (\"embed\" for embeddings)\n",
    "    use_rep : str, default=\"X_pca\"\n",
    "        Key in adata.obsm for the embedding to use\n",
    "    perplexity : int, default=30\n",
    "        Perplexity parameter for neighborhood definition\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Normalized mean cLISI score across all cells (0-1 range)\n",
    "    \"\"\"\n",
    "    if type == \"embed\":\n",
    "        print(\"Using embed\")\n",
    "        if use_rep not in adata.obsm:\n",
    "            raise ValueError(f\"Embedding {use_rep} not found in adata.obsm\")\n",
    "        X = adata.obsm[use_rep]\n",
    "    else:\n",
    "        X = adata.X\n",
    "    \n",
    "    if label_key not in adata.obs:\n",
    "        raise ValueError(f\"Label key {label_key} not found in adata.obs\")\n",
    "    \n",
    "    # Get number of unique cell types for normalization\n",
    "    n_celltypes = len(adata.obs[label_key].unique())\n",
    "    \n",
    "    print(\"Computing LISI\")\n",
    "    # Compute LISI scores\n",
    "    lisi_scores = compute_lisi(X, adata.obs, label_key, perplexity)\n",
    "    \n",
    "    # Normalize by number of cell types (perfect mixing = 1.0, no mixing = 1/n_celltypes)\n",
    "    normalized_scores = (lisi_scores - 1) / (n_celltypes - 1)\n",
    "    \n",
    "    # Return mean normalized cLISI score\n",
    "    return np.mean(normalized_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset_by_celltype(adata, batch_key='tech', celltype_key='celltype', \n",
    "                               random_state=42, top_k=None, min_cell=None):\n",
    "    \"\"\"\n",
    "    Balance dataset so that each technology/batch has the same number of cells for each cell type.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Annotated data object\n",
    "    batch_key : str, default 'tech'\n",
    "        Key in adata.obs containing batch/technology information\n",
    "    celltype_key : str, default 'celltype'\n",
    "        Key in adata.obs containing cell type information\n",
    "    random_state : int, default 42\n",
    "        Random seed for reproducible sampling\n",
    "    top_k : int, optional\n",
    "        Keep only the top k most abundant cell types (by total count across all batches)\n",
    "    min_cell : int, optional\n",
    "        Remove batches that have fewer than min_cell cells for any cell type\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    AnnData\n",
    "        Balanced dataset with equal cell type representation across batches\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Get batch and cell type combinations\n",
    "    batch_celltype_counts = adata.obs.groupby([batch_key, celltype_key]).size().reset_index(name='count')\n",
    "    print(\"Original cell counts per batch and cell type:\")\n",
    "    print(batch_celltype_counts.pivot(index=celltype_key, columns=batch_key, values='count').fillna(0))\n",
    "    \n",
    "    # Filter by top_k most abundant cell types if specified\n",
    "    if top_k is not None:\n",
    "        total_counts_per_celltype = adata.obs[celltype_key].value_counts()\n",
    "        top_k_celltypes = total_counts_per_celltype.head(top_k).index.tolist()\n",
    "        print(f\"\\nKeeping top {top_k} most abundant cell types: {top_k_celltypes}\")\n",
    "        \n",
    "        # Filter adata to only include top k cell types\n",
    "        mask = adata.obs[celltype_key].isin(top_k_celltypes)\n",
    "        adata = adata[mask].copy()\n",
    "        \n",
    "        # Recalculate counts after filtering\n",
    "        batch_celltype_counts = adata.obs.groupby([batch_key, celltype_key]).size().reset_index(name='count')\n",
    "        print(\"Cell counts after top_k filtering:\")\n",
    "        print(batch_celltype_counts.pivot(index=celltype_key, columns=batch_key, values='count').fillna(0))\n",
    "    \n",
    "    # Filter by min_cell if specified - drop batches that don't have enough cells\n",
    "    if min_cell is not None:\n",
    "        # Create pivot table to check each batch-celltype combination\n",
    "        count_matrix = batch_celltype_counts.pivot(index=celltype_key, columns=batch_key, values='count').fillna(0)\n",
    "        \n",
    "        # Find batches that have at least min_cell cells for ALL cell types\n",
    "        valid_batches = []\n",
    "        for batch in count_matrix.columns:\n",
    "            batch_counts = count_matrix[batch]\n",
    "            if (batch_counts >= min_cell).all():\n",
    "                valid_batches.append(batch)\n",
    "        \n",
    "        print(f\"\\nBatches with at least {min_cell} cells for each cell type: {valid_batches}\")\n",
    "        \n",
    "        if len(valid_batches) == 0:\n",
    "            raise ValueError(f\"No batches have at least {min_cell} cells for all cell types\")\n",
    "        \n",
    "        # Filter adata to only include valid batches\n",
    "        mask = adata.obs[batch_key].isin(valid_batches)\n",
    "        adata = adata[mask].copy()\n",
    "        \n",
    "        # Recalculate counts after filtering\n",
    "        batch_celltype_counts = adata.obs.groupby([batch_key, celltype_key]).size().reset_index(name='count')\n",
    "        print(\"Cell counts after min_cell batch filtering:\")\n",
    "        print(batch_celltype_counts.pivot(index=celltype_key, columns=batch_key, values='count').fillna(0))\n",
    "    \n",
    "    # Find minimum count for each cell type across remaining batches\n",
    "    min_counts_per_celltype = batch_celltype_counts.groupby(celltype_key)['count'].min()\n",
    "    print(f\"\\nMinimum counts per cell type across remaining batches:\")\n",
    "    print(min_counts_per_celltype)\n",
    "    \n",
    "    # Sample cells to balance the dataset\n",
    "    balanced_indices = []\n",
    "    \n",
    "    for celltype in adata.obs[celltype_key].unique():\n",
    "        min_count = min_counts_per_celltype[celltype]\n",
    "        \n",
    "        # Skip cell types that don't exist in all remaining batches\n",
    "        if min_count == 0:\n",
    "            print(f\"Warning: Cell type '{celltype}' not present in all remaining batches. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        for batch in adata.obs[batch_key].unique():\n",
    "            # Get all cells of this type in this batch\n",
    "            mask = (adata.obs[celltype_key] == celltype) & (adata.obs[batch_key] == batch)\n",
    "            cell_indices = np.where(mask)[0]\n",
    "            \n",
    "            if len(cell_indices) == 0:\n",
    "                print(f\"Warning: No cells of type '{celltype}' in batch '{batch}'. Skipping.\")\n",
    "                continue\n",
    "            elif len(cell_indices) < min_count:\n",
    "                print(f\"Warning: Only {len(cell_indices)} cells of type '{celltype}' in batch '{batch}', need {min_count}.\")\n",
    "                # Take all available cells\n",
    "                balanced_indices.extend(cell_indices)\n",
    "            else:\n",
    "                # Randomly sample min_count cells\n",
    "                sampled_indices = np.random.choice(cell_indices, size=min_count, replace=False)\n",
    "                balanced_indices.extend(sampled_indices)\n",
    "    \n",
    "    # Create balanced dataset\n",
    "    balanced_adata = adata[balanced_indices].copy()\n",
    "    \n",
    "    # Verify the balancing\n",
    "    balanced_counts = balanced_adata.obs.groupby([batch_key, celltype_key]).size().reset_index(name='count')\n",
    "    print(f\"\\nFinal balanced cell counts per batch and cell type:\")\n",
    "    print(balanced_counts.pivot(index=celltype_key, columns=batch_key, values='count').fillna(0))\n",
    "    \n",
    "    print(f\"\\nOriginal dataset: {adata.n_obs} cells\")\n",
    "    print(f\"Final balanced dataset: {balanced_adata.n_obs} cells\")\n",
    "    print(f\"Number of batches retained: {len(balanced_adata.obs[batch_key].unique())}\")\n",
    "    print(f\"Number of cell types retained: {len(balanced_adata.obs[celltype_key].unique())}\")\n",
    "    \n",
    "    return balanced_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the torch random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"/workspaces/data/human_pancreas_norm_complexBatch.h5ad\")\n",
    "\n",
    "# reduce the dataset so that each technology has the same number of cells of each cell type\n",
    "\n",
    "adata.raw = adata\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "sc.pp.filter_cells(adata, min_genes=300)\n",
    "sc.pp.filter_genes(adata, min_cells=5)\n",
    "sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000, batch_key='tech')\n",
    "adata = adata[:, adata.var['highly_variable']]\n",
    "multi_resolution_cluster(adata, resolution1 = 1, method = 'Leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the balancing function with filtering\n",
    "print(\"Balancing dataset with filtering...\")\n",
    "\n",
    "# Example usage with both parameters:\n",
    "# - Keep only top 10 most abundant cell types\n",
    "# - Require at least 50 cells per cell type per batch\n",
    "adata_balanced = balance_dataset_by_celltype(\n",
    "    adata, \n",
    "    batch_key='tech', \n",
    "    celltype_key='celltype', \n",
    "    random_state=42,\n",
    "    top_k=4,        # Keep only top 10 cell types\n",
    "    min_cell=50      # Require at least 50 cells per batch per cell type\n",
    ")\n",
    "\n",
    "# Update adata to use the balanced version\n",
    "adata = adata_balanced.copy()\n",
    "print(f\"\\nDataset balanced and filtered. New shape: {adata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = train_integration_model(adata, batch_key = 'tech', z_dim=256, d_coef = 32, epochs=500, critic=True, disc_iter=10)\n",
    "obtain_embeddings(adata, VAE.to(\"cuda:0\"))\n",
    "sc.pp.neighbors(adata, use_rep=\"X_scCRAFT\")\n",
    "plot_umap_by_technology(adata, batch_key='tech', color_key='celltype')\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "\n",
    "ilisi_score = ilisi_graph(adata, batch_key=\"tech\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"iLISI score (1 is best): {ilisi_score:.4f}\")\n",
    "\n",
    "clisi_score = clisi_graph(adata, label_key=\"celltype\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"cLISI score (0 is best): {clisi_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = train_integration_model(adata, batch_key = 'tech', z_dim=256, d_coef = 0.4, epochs=500, critic=True, disc_iter=10)\n",
    "obtain_embeddings(adata, VAE.to(\"cuda:0\"))\n",
    "sc.pp.neighbors(adata, use_rep=\"X_scCRAFT\")\n",
    "plot_umap_by_technology(adata, batch_key='tech', color_key='celltype')\n",
    "\n",
    "print(scib.me.silhouette(adata, label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "print(scib.me.silhouette_batch(adata, batch_key=\"tech\", label_key=\"celltype\", embed=\"X_scCRAFT\", scale=True))\n",
    "\n",
    "ilisi_score = ilisi_graph(adata, batch_key=\"tech\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"iLISI score (1 is best): {ilisi_score:.4f}\")\n",
    "\n",
    "clisi_score = clisi_graph(adata, label_key=\"celltype\", type=\"embed\", use_rep=\"X_scCRAFT\")\n",
    "print(f\"cLISI score (0 is best): {clisi_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
